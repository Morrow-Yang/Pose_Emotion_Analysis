# Pose_Emotion_Analysis

Pose-based emotion analysis with AlphaPose (2D) and BVH motion capture (3D). This repository includes feature extraction, statistical analysis (v1–v5), and innovation scripts for new features and temporal analysis.

## Instructions
This section explains how to run the key analysis and innovation scripts.

### 2D Temporal Analysis (CAER-S)
Extract kinetic energy (velocity/acceleration) from AlphaPose JSON results.
```bash
python scripts/innovation/temporal_motion_analysis.py --root "outputs/alphapose/outputs/CAER-S/train" --out "outputs/analysis/temporal/v1"
```
**Arguments:**
- `--root`: Path to the directory containing emotion sub-folders (Angry, Happy, etc.) with `alphapose-results.json`.
- `--out`: Directory where CSV features and summary statistics will be saved.

### 2D Visualization
Generate 4-panel research plots (Velocity, Acceleration, Comparison).
```bash
python scripts/innovation/plot_temporal_results.py --csv "outputs/analysis/temporal/v1/temporal_motion_features.csv" --out "outputs/analysis/temporal/v1"
```
**Arguments:**
- `--csv`: Path to the motion features CSV generated by the previous step.
- `--out`: Directory to save the PNG/PDF plots.

### Full CAER Videos @10fps (train split) — unified subject alignment
This mirrors the CAER-S pipeline but starts from videos, keeps one person per frame, and fuses geometry+temporal features.

1) Frame extraction (10 fps):
```bash
ffmpeg -i raw/CAER/<emotion>/<video>.mp4 -vf fps=10 outputs/frames/CAER/<emotion>/%04d.png
```

2) Run AlphaPose on frames to produce `alphapose-results.json` under each emotion folder:
```
outputs/alphapose/outputs/CAER/<emotion>/alphapose-results.json
```

3) Keep top-1 person per frame (score, then bbox area):
```bash
python scripts/features/filter_top1_alphapose.py \
  --input  outputs/alphapose/outputs/CAER/<emotion>/alphapose-results.json \
  --output outputs/alphapose/outputs/CAER/<emotion>/alphapose-results.top1.json
```
Use the *.top1.json for both geometry and temporal steps to ensure the same subject is used.

4) Temporal (velocity/acceleration with image_id for merging):
```bash
python scripts/innovation/temporal_motion_analysis.py \
  --root outputs/alphapose/outputs/CAER \
  --out  outputs/analysis/temporal/caer_v1
```

5) Geometry (v4) from the filtered JSON:
```bash
python scripts/analysis/analysis_v4.py \
  --root outputs/alphapose/outputs/CAER \
  --json_name alphapose-results.top1.json \
  --out_dir outputs/analysis/analysis/caer_v4
```

6) Merge geometry + temporal on (emotion, image_id): produces `pose_features_caer_with_temporal.csv` in `outputs/analysis/analysis/caer_v4/`.

7) Fused analysis (PCA, t-SNE, KMeans, Kruskal, RF baseline):
```bash
python scripts/analysis/analysis_v4.py \
  --root outputs/alphapose/outputs/CAER \
  --precomputed_csv outputs/analysis/analysis/caer_v4/pose_features_caer_with_temporal.csv \
  --out_dir outputs/analysis/analysis/caer_v4_with_temporal \
  --json_name alphapose-results.top1.json
```

Tips:
- If KMeans warns about MKL memory leak on Windows, set `OMP_NUM_THREADS=6` before running.
- Subject alignment: the top1 filter is required; otherwise geometry and temporal may refer to different people in the same frame.

### 3D BVH Analysis (Ground Truth)
Parse 3D motion capture files using Forward Kinematics to calculate real-world velocity.
```bash
python scripts/innovation/bvh_temporal_analysis.py --root "data/raw/kinematic-dataset-of-actors..." --out "outputs/analysis/temporal_3d/v1"
```
**Arguments:**
- `--root`: Root directory of the Kinematic Dataset (containing the `BVH/` folder and `file-info.csv`).
- `--out`: Directory to save the 3D features and summary.

### Cross-Modal Validation
Compare 2D estimates from AlphaPose against 3D Ground Truth from BVH.
```bash
python scripts/innovation/compare_2d_3d.py --csv2d "outputs/analysis/temporal/v1/temporal_motion_features.csv" --csv3d "outputs/analysis/temporal_3d/v1/bvh_temporal_summary.csv" --out "outputs/analysis/validation"
```
**Arguments:**
- `--csv2d`: Path to the 2D features CSV.
- `--csv3d`: Path to the 3D features CSV.
- `--out`: Directory to save correlation plots.

### Emotion Classification Baseline (Research Innovation)
Train a Machine Learning model (Random Forest) to evaluate the discriminative power of handcrafted body features across 7 emotions.
```bash
python scripts/innovation/emotion_classifier_v1.py --csv "outputs/analysis/temporal/v1/temporal_motion_features.csv" --out "outputs/experiments/classification_v1"
```
**Arguments:**
- `--csv`: Path to the input features CSV (static + temporal).
- `--out`: Directory to save the classification report and feature importance plots.

## Project Structure
```
AIemotion/
  data/
    raw/                    # original datasets (not tracked)
      CAER-S/
      kinematic-dataset-of-actors-expressing-emotions-2.1.0/
    external/               # third-party tools (not tracked)
      AlphaPose-master/
  outputs/                  # generated outputs (not tracked)
    alphapose/
    features/
    analysis/
      temporal/             # 2D kinetic results
      temporal_3d/          # 3D BVH results
      validation/           # 2D/3D comparison plots
    innovation/
  scripts/
    analysis/               # analysis_v1-v5, run_all_v1_v5
    features/               # metrics-2.py, alphapose_extra_features.py, bvh_*.py
    innovation/             # Core scripts for temporal and 3D analysis
      temporal_motion_analysis.py  # 2D extractor
      bvh_temporal_analysis.py     # 3D extractor
      compare_2d_3d.py             # Validation
      utils_bvh_parser.py         # 3D Parser engine
  README.md
```

## Data Sources
- **CAER-S**: Contextualized Affect Representations from Scenes.
- **Kinematic Dataset of Actors Expressing Emotions (v2.1.0)**: BVH motion capture sequences.

> Note: Datasets are not included in this repo. Please download them from their official sources.

## AlphaPose Models
AlphaPose models and weights are not included. Use the official AlphaPose repository to download:
- YOLO detector weights
- FastPose model
